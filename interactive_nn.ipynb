{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #csv-files and tables\n",
    "import tensorflow as tf #neural network\n",
    "# import keras.backend as K\n",
    "#create graphics\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# #utils for working with neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# #interactive in jupyter notebook\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import levenberg_marquardt as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate widgets in terminal\n",
    "# jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets\n",
    "dataset_0 = pd.read_csv('data/simple.csv')\n",
    "dataset_0.name = 'simple'\n",
    "dataset_1 = pd.read_csv('data/iris_new.csv')\n",
    "dataset_1.name = 'iris'\n",
    "dataset_2 = pd.read_csv('data/cancer.csv')\n",
    "dataset_2.name = 'cancer'\n",
    "dataset_3 = pd.read_csv('data/glass.csv')\n",
    "dataset_3.name = 'glass'\n",
    "dataset_4 = pd.read_csv('data/thyroid.csv')\n",
    "dataset_4.name = 'thyroid'\n",
    "dataset_5 = pd.read_csv('data/vine.csv')\n",
    "dataset_5.name = 'vine'\n",
    "dataset_6 = pd.read_csv('data/train_hackaton.csv')\n",
    "dataset_6.name = 'hackaton'\n",
    "dataset_7 = pd.read_excel('data/data_spectrum1.xlsx', sheet_name=\"Лист2\")\n",
    "dataset_7.name = 'sensor'\n",
    "dataset_7_test = pd.read_excel('data/data_spectrum_kubinka15_1.xlsx', sheet_name=\"Лист2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_hack = pd.read_csv('data/test_hackaton.csv')\n",
    "input_data_test_hack = dataset_test_hack.iloc[:, :22]\n",
    "output_data_test_hack = dataset_test_hack.iloc[:, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dataset_7_test = dataset_7_test.iloc[:,10:40]\n",
    "out_dataset_7_test = dataset_7_test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dataset_7_test = in_dataset_7_test/in_dataset_7_test.max().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_hack = []\n",
    "for i in output_data_test_hack.values:\n",
    "    max_test_hack.append(tf.math.argmax(i).numpy() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data markup\n",
    "#iloc -> select data on table\n",
    "\n",
    "input_data_0 = dataset_0.iloc[:, :2]\n",
    "output_data_0 = dataset_0.iloc[:, -4:]\n",
    "io0 = [input_data_0.values, output_data_0.values]\n",
    "\n",
    "input_data_1 = dataset_1.iloc[:, :4]\n",
    "output_data_1 = dataset_1.iloc[:, -3:]\n",
    "io1 = [input_data_1.values, output_data_1.values]\n",
    "\n",
    "input_data_2 = dataset_2.iloc[:, :9]\n",
    "output_data_2 = dataset_2.iloc[:, -2:]\n",
    "io2 = [input_data_2.values, output_data_2.values]\n",
    "\n",
    "input_data_3 = dataset_3.iloc[:, :9]\n",
    "output_data_3 = dataset_3.iloc[:, -2:]\n",
    "io3 = [input_data_3.values, output_data_3.values]\n",
    "\n",
    "input_data_4 = dataset_4.iloc[:, :21]\n",
    "output_data_4 = dataset_4.iloc[:, -3:]\n",
    "io4 = [input_data_4.values, output_data_4.values]\n",
    "\n",
    "input_data_5 = dataset_5.iloc[:, :13]\n",
    "output_data_5 = dataset_5.iloc[:, -3:]\n",
    "io5 = [input_data_5.values, output_data_5.values]\n",
    "\n",
    "input_data_6 = dataset_6.iloc[:, :22]\n",
    "output_data_6 = dataset_6.iloc[:, -5:]\n",
    "io6 = [input_data_6.values, output_data_6.values]\n",
    "\n",
    "input_data_7 = dataset_7.iloc[:, 10:40]\n",
    "output_data_7 = dataset_7.iloc[:, -1:]\n",
    "io7 = [input_data_7.values, output_data_7.values]\n",
    "\n",
    "# io = [io0, io1, io2, io3, io4, io5, io6, io7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_7 = input_data_7/input_data_7.max().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = [io0, io1, io2, io3, io4, io5, io6, io7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary selection by name\n",
    "dict_datasets = {\n",
    " dataset_0.name:(dataset_0,io0),\n",
    " dataset_1.name:(dataset_1,io1),\n",
    " dataset_2.name:(dataset_2,io2),\n",
    " dataset_3.name:(dataset_3,io3),\n",
    " dataset_4.name:(dataset_4,io4),\n",
    " dataset_5.name:(dataset_5,io5),\n",
    " dataset_6.name:(dataset_6,io6),\n",
    " dataset_7.name:(dataset_7,io7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_easy(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f68b3ae39e0492f8d07f18f574c95c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset_name', options=('simple', 'iris', 'cancer', 'glass', 'thyr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual\n",
    "def learning_datasets(\n",
    "        dataset_name = dict_datasets.keys(),\n",
    "        test_size = (0.05,1,0.05),\n",
    "        batch_size = widgets.IntText(\n",
    "            value=4,\n",
    "            disabled=False\n",
    "        ),\n",
    "        activation_1_layer = ['tanh', 'sigmoid', 'relu'],\n",
    "        kernel_reg_1_layer = widgets.FloatText(\n",
    "            value=0.0,\n",
    "            disabled=False\n",
    "        ),\n",
    "        dropout_1 =  widgets.FloatText(\n",
    "            value=0.0,\n",
    "            disabled=False\n",
    "        ), \n",
    "        activation_2_layer = ['tanh', 'sigmoid', 'relu'],\n",
    "        kernel_reg_2_layer = widgets.FloatText(\n",
    "            value=0.0,\n",
    "            disabled=False\n",
    "        ),\n",
    "        dropout_2 =  widgets.FloatText(\n",
    "            value=0.0,\n",
    "            disabled=False\n",
    "        ),\n",
    "        neurons_1_layer = (5,100,5),\n",
    "        neurons_2_layer = (5,100,5),\n",
    "        optimizer = ['adam', 'sgd', 'RMSprop'],\n",
    "        learning_rate = widgets.FloatText(\n",
    "            value=0.1,\n",
    "            disabled=False\n",
    "        ),\n",
    "        loss = ['mse', 'mae', 'categorical_crossentropy'],\n",
    "        metrics = ['accuracy', 'mae'],\n",
    "        epochs = widgets.IntText(\n",
    "            value=100,\n",
    "            disabled=False\n",
    "        )\n",
    "    ):\n",
    "    \n",
    "    head = dict_datasets[dataset_name][0].head()   #first 5 rows in dataset\n",
    "    Q = dict_datasets[dataset_name][1][0].shape[0] #rows -> int\n",
    "    m = dict_datasets[dataset_name][1][0].shape[1] #input columns -> int\n",
    "    p = dict_datasets[dataset_name][1][1].shape[1] #output columns -> int\n",
    "    \n",
    "    input_data = dict_datasets[dataset_name][1][0]\n",
    "    output_data = dict_datasets[dataset_name][1][1]\n",
    "    \n",
    "    fig1 = go.Figure()\n",
    "    fig2 = go.Figure()\n",
    "    fig3 = go.Figure()\n",
    "    \n",
    "    x_axis = np.linspace(1, epochs, epochs)\n",
    "    val_metrics = f'val_{metrics}'\n",
    "    \n",
    "    list_loss = []\n",
    "    list_metric = []\n",
    "    \n",
    "    #create model neural network\n",
    "    for _ in range(5):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            input_data, \n",
    "            output_data,\n",
    "            test_size=test_size\n",
    "        )\n",
    "        X_train, X_test, Y_train, Y_test = X_train.astype(np.float32),X_test.astype(np.float32),Y_train.astype(np.float32),Y_test.astype(np.float32)\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(\n",
    "                neurons_1_layer, \n",
    "                input_dim=m,\n",
    "                activation=activation_1_layer,\n",
    "                kernel_regularizer = tf.keras.regularizers.l2(float(kernel_reg_1_layer)),\n",
    "                kernel_initializer='glorot_uniform' #xavier initialization\n",
    "            ),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_1),\n",
    "            tf.keras.layers.Dense(\n",
    "                neurons_2_layer, \n",
    "                activation=activation_2_layer,\n",
    "                kernel_regularizer = tf.keras.regularizers.l2(float(kernel_reg_2_layer)),\n",
    "                kernel_initializer='glorot_uniform'\n",
    "            ),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_2),\n",
    "            tf.keras.layers.Dense(\n",
    "                1, \n",
    "                activation='sigmoid',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "#     error_num_val = [int(np.ceil((100*(1 - i))/(100./len(X_test)))) for i in history.history['val_accuracy']]\n",
    "        \n",
    "        model.compile(optimizer=optimizer,\n",
    "#                   loss=[tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)],\n",
    "                      loss = [loss],\n",
    "#                   metrics=[tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)]\n",
    "#                     metrics = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "                      metrics = [metrics]\n",
    "                )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "#             validation_split=0.1,\n",
    "#             validation_data=(input_data_test_hack.values, output_data_test_hack.values),\n",
    "            validation_data=(in_dataset_7_test,out_dataset_7_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0\n",
    "        )\n",
    "#         print(history.history)\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_axis,\n",
    "                y=history.history['loss'],\n",
    "                name=f'Train sample {_}',\n",
    "                 line=dict(color='green')\n",
    "            )\n",
    "        )\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_axis,\n",
    "                y=history.history['val_loss'],\n",
    "                name=f'Valid sample {_}',\n",
    "                line=dict(color='black')\n",
    "            )\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_axis,\n",
    "#                 y=history.history['mean_absolute_error'],\n",
    "                y=history.history[metrics],\n",
    "                name=f'Train sample {_}',\n",
    "                line=dict(color='green')\n",
    "            )\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_axis,\n",
    "#                 y=history.history['val_mean_absolute_error'],\n",
    "                y=history.history[val_metrics],\n",
    "                name=f'Valid sample {_}',\n",
    "                line=dict(color='black')\n",
    "            )\n",
    "        )\n",
    "#     fig3.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=x_axis,\n",
    "#             y=error_num_val,\n",
    "#             name='Valid sample'\n",
    "#         )\n",
    "#     )\n",
    "#     print(history.history)\n",
    "    \n",
    "        eval_step = model.evaluate(in_dataset_7_test,out_dataset_7_test, batch_size=batch_size, verbose=0)\n",
    "        list_loss.append(eval_step[0])\n",
    "        list_metric.append(eval_step[1])\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='Loss',\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        yaxis=dict(title_text=f'{loss}'),\n",
    "        xaxis=dict(title_text='Epoch')\n",
    "    )\n",
    "    fig2.update_layout(\n",
    "        title='Metrics',\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        yaxis=dict(title_text=f'{metrics}'),\n",
    "        xaxis=dict(title_text='Epoch')\n",
    "    )\n",
    "#     fig3.update_layout(\n",
    "#         title='Errors',\n",
    "#         autosize=False,\n",
    "#         width=800,\n",
    "#         height=500,\n",
    "#         yaxis=dict(title_text='Errors'),\n",
    "#         xaxis=dict(title_text='Epoch')\n",
    "#     )\n",
    "    \n",
    "    print(f'{Q} sample with {m} input columns and {p} output')\n",
    "    print(f'Size of train sample: {len(X_train)}')\n",
    "    print(f'Size of test sample: {len(X_test)}')\n",
    "    \n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "#     fig3.show()\n",
    "        \n",
    "    ev = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "#     print(f'MAE test: {mean_absolute_error(predictions, Y_test)}')\n",
    "#     print(f'Accuracy test: {accuracy_score(predictions, Y_test)}')\n",
    "    \n",
    "    if dataset_name == 'hackaton':\n",
    "        predictions_test_hackaton = model.predict(input_data_test_hack)\n",
    "        pred_max = []\n",
    "        for i in predictions_test_hackaton:\n",
    "            pred_max.append(tf.math.argmax(i).numpy() + 1)\n",
    "        print(f'Prediction labels {pred_max}')\n",
    "        mae_sklearn_hack = mean_absolute_error(pred_max, max_test_hack)\n",
    "#         print(predictions_test_hackaton)\n",
    "        print(f'Sklearn test hackaton mae {mae_sklearn_hack}')\n",
    "    \n",
    "#     mae_sklearn = mean_absolute_error(predictions, Y_test)\n",
    "\n",
    "    #     error_num_end = int(np.ceil((100*(1 - ev[1]))/(100./len(X_test))))\n",
    "    \n",
    "#     print(f'Sklearn test mae {mae_sklearn}')\n",
    "#     print(f'{metrics} test samples: {ev}')\n",
    "\n",
    "    #     print(f'Errors : {error_num_end} ')\n",
    "    \n",
    "    list_loss_lm = []\n",
    "    list_metric_lm = []\n",
    "    \n",
    "    print(f\"{optimizer} \")\n",
    "    print(f'MEAN {loss} {sum(list_loss)/len(list_loss)} MEAN {metrics} {sum(list_metric)/len(list_metric)}')\n",
    "    print(f'MAX {loss} {max(list_loss)} MAX {metrics} {max(list_metric)}')\n",
    "    print(f'MIN {loss} {min(list_loss)} MIN {metrics} {min(list_metric)}')\n",
    "    \n",
    "    print(f\"------------------ LEVENBERG-MARQUARDT -----------------\")\n",
    "    \n",
    "    fig4 = go.Figure()\n",
    "    fig5 = go.Figure()\n",
    "\n",
    "    for _ in range(5):\n",
    "        \n",
    "        model_wrapper = lm.ModelWrapper(tf.keras.models.clone_model(model))\n",
    "        model_wrapper.compile(\n",
    "#             solve_method='qr,\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "            loss=lm.MeanSquaredError(),\n",
    "            metrics = [metrics]\n",
    "        )\n",
    "        history_lm = model_wrapper.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=epochs,\n",
    "            verbose=0\n",
    "        )\n",
    "#         print(model_wrapper.train_step())\n",
    "#         print(history_lm)\n",
    "#         break\n",
    "        if dataset_name == 'hackaton':\n",
    "            pred_lm = model_wrapper.predict(input_data_test_hack)\n",
    "            pred_max_lm = []\n",
    "            for i in pred_lm:\n",
    "                pred_max_lm.append(tf.math.argmax(i).numpy() + 1)\n",
    "            print(f'Prediction labels lm {pred_max_lm}')\n",
    "            mae_sklearn_hack_lm = mean_absolute_error(pred_max_lm, max_test_hack)\n",
    "            print(f'Sklearn test hackaton mae lm {mae_sklearn_hack_lm}')\n",
    "        \n",
    "#         fig4.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=x_axis,\n",
    "#                 y=history_lm.history['loss'],\n",
    "#                 name=f'Train sample {_}',\n",
    "#                  line=dict(color='green')\n",
    "#             )\n",
    "#         )\n",
    "#         fig4.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=x_axis,\n",
    "#                 y=history_lm.history['val_loss'],\n",
    "#                 name=f'Valid sample {_}',\n",
    "#                 line=dict(color='black')\n",
    "#             )\n",
    "#         )\n",
    "#         fig5.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=x_axis,\n",
    "# #                 y=history.history['mean_absolute_error'],\n",
    "#                 y=history_lm.history[metrics],\n",
    "#                 name=f'Train sample {_}',\n",
    "#                 line=dict(color='green')\n",
    "#             )\n",
    "#         )\n",
    "#         fig5.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=x_axis,\n",
    "# #                 y=history.history['val_mean_absolute_error'],\n",
    "#                 y=history_lm.history[val_metrics],\n",
    "#                 name=f'Valid sample {_}',\n",
    "#                 line=dict(color='black')\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "        \n",
    "        ev_lm = model_wrapper.evaluate(in_dataset_7_test,out_dataset_7_test, batch_size=batch_size, verbose=0)\n",
    "        list_loss_lm.append(ev_lm[0])\n",
    "        list_metric_lm.append(ev_lm[1])\n",
    "        \n",
    "        #     print(ev_lm)\n",
    "    \n",
    "#     fig4.update_layout(\n",
    "#         title='Loss',\n",
    "#         autosize=False,\n",
    "#         width=800,\n",
    "#         height=500,\n",
    "#         yaxis=dict(title_text=f'{loss}'),\n",
    "#         xaxis=dict(title_text='Epoch')\n",
    "#     )\n",
    "#     fig5.update_layout(\n",
    "#         title='Metrics',\n",
    "#         autosize=False,\n",
    "#         width=800,\n",
    "#         height=500,\n",
    "#         yaxis=dict(title_text=f'{metrics}'),\n",
    "#         xaxis=dict(title_text='Epoch')\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    print(f\"LEVENBERG-MARQUARDT\")\n",
    "    print(f'MEAN {loss} {sum(list_loss_lm)/len(list_loss_lm)} MEAN {metrics} {sum(list_metric_lm)/len(list_metric_lm)}')\n",
    "    print(f'MAX {loss} {max(list_loss_lm)} MAX {metrics} {max(list_metric_lm)}')\n",
    "    print(f'MIN {loss} {min(list_loss_lm)} MIN {metrics} {min(list_metric_lm)}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
